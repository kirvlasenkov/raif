{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, os.path\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_floor_replace = {\n",
    "                     'подвал, 1': 1, \n",
    "                     'подвал': -1, \n",
    "                     'цоколь, 1': 1, \n",
    "                     '1,2,антресоль': 2, \n",
    "                     'цоколь': 0, \n",
    "                     'тех.этаж (6)': 6, \n",
    "                     'Подвал': -1, \n",
    "                     'Цоколь': 0, \n",
    "                     'фактически на уровне 1 этажа': 1, \n",
    "                     '1,2,3': 3, \n",
    "                     '1, подвал': 1, \n",
    "                     '1,2,3,4': 4, \n",
    "                     '1,2': 2, \n",
    "                     '1,2,3,4,5': 5, \n",
    "                     '5, мансарда': 5, \n",
    "                     '1-й, подвал': 1, \n",
    "                     '1, подвал, антресоль': 1, \n",
    "                     'мезонин': 2, \n",
    "                     'подвал, 1-3': 3, \n",
    "                     '1 (Цокольный этаж)': 0, \n",
    "                     '3, Мансарда (4 эт)': 4, \n",
    "                     'подвал,1': 1, \n",
    "                     '1, антресоль': 1, \n",
    "                     '1-3': 3, \n",
    "                     'мансарда (4эт)': 4, \n",
    "                     '1, 2.': 2, \n",
    "                     'подвал , 1 ': 1, \n",
    "                     '1, 2': 2, \n",
    "                     'подвал, 1,2,3': 3, \n",
    "                     '1 + подвал (без отделки)': 1, \n",
    "                     'мансарда': 1, \n",
    "                     '2,3': 3, \n",
    "                     '4, 5': 5, \n",
    "                     '1-й, 2-й': 2, \n",
    "                     '1 этаж, подвал': 1, \n",
    "                     '1, цоколь': 1, \n",
    "                     'подвал, 1-7, техэтаж': 7, \n",
    "                     '3 (антресоль)': 3, \n",
    "                     '1, 2, 3': 3, \n",
    "                     'Цоколь, 1,2(мансарда)': 2, \n",
    "                     'подвал, 3. 4 этаж': 4, \n",
    "                     'подвал, 1-4 этаж': 4, \n",
    "                     'подва, 1.2 этаж': 4, \n",
    "                     '2, 3': 3, \n",
    "                     '7,8': 8, \n",
    "                     '1 этаж': 1, \n",
    "                     '1-й': 1, \n",
    "                     '3 этаж': 3, \n",
    "                     '4 этаж': 4, \n",
    "                     '5 этаж': 5, \n",
    "                     'подвал,1,2,3,4,5': 5, \n",
    "                     'подвал, цоколь, 1 этаж': 1, \n",
    "                     '3, мансарда': 3,\n",
    "                    ' 1, 2, Антресоль': 2,\n",
    "                    ' 1-2, подвальный': 2,\n",
    "                    '1 (по док-м цоколь)': 1,\n",
    "                    '1, 2 этаж': 2,\n",
    "                    '1, 2, 3, мансардный': 3,\n",
    "                    '1,2 ': 2,\n",
    "                    '1,2,3 этаж, подвал': 3,\n",
    "                    '1,2,3, антресоль, технический этаж': 3,\n",
    "                    '1,2,3,4, подвал': 4,\n",
    "                    '1,2,подвал ': 2,\n",
    "                    '1-3 этажи, цоколь (188,4 кв.м), подвал (104 кв.м)': 3,\n",
    "                    '1-7': 7,\n",
    "                    '2, 3, 4, тех.этаж': 4,\n",
    "                    '2-й': 2,\n",
    "                    '3 этаж, мансарда (4 этаж)': 4,\n",
    "                    '3, 4': 4,\n",
    "                    '3,4': 4,\n",
    "                    '5(мансарда)': 5,\n",
    "                    'Техническое подполье': -1,\n",
    "                    'подвал, 1 и 4 этаж': 4,\n",
    "                    'подвал, 1, 2': 2,\n",
    "                    'подвал, 1, 2, 3': 3,\n",
    "                    'подвал, 2': 2,\n",
    "                    'подвал,1,2,3': 3,\n",
    "                    'технический этаж,5,6': 6,\n",
    "                    'цоколь, 1, 2,3,4,5,6': 6,\n",
    "                    'цокольный': 0,\n",
    "                    'цокольный, 1,2':2\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2974, 76)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/data/train.csv')\n",
    "test_data = pd.read_csv('./data/data/test.csv')\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(value):\n",
    "    try:\n",
    "        if type(float(value)) != 'float':\n",
    "            return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2974, 79)\n"
     ]
    }
   ],
   "source": [
    "train_data['day'] = pd.to_datetime(train_data['date']).dt.day\n",
    "test_data['day'] = pd.to_datetime(test_data['date']).dt.day\n",
    "\n",
    "train_data['floor_isnull'] = np.where(train_data['floor'].isnull(), 0, 1)\n",
    "test_data['floor_isnull'] = np.where(test_data['floor'].isnull(), 0, 1)\n",
    "\n",
    "train_data['floor_is_float'] = np.where(train_data['floor'].apply(lambda x: is_float(x)), 1, 0)\n",
    "test_data['floor_is_float'] = np.where(test_data['floor'].apply(lambda x: is_float(x)), 1, 0)\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2974, 82)\n"
     ]
    }
   ],
   "source": [
    "train_data['address'] = train_data['city'] + ' ' + train_data['street']\n",
    "test_data['address'] = test_data['city'] + ' ' + test_data['street']\n",
    "\n",
    "train_data['log_total_square'] = np.log(train_data['total_square'])\n",
    "test_data['log_total_square'] = np.log(test_data['total_square'])\n",
    "        \n",
    "train_data['clear_city'] = train_data['city'].apply(lambda x: x.split(', ')[-1].strip())\n",
    "test_data['clear_city'] = test_data['city'].apply(lambda x: x.split(', ')[-1].strip())\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2974, 82)\n"
     ]
    }
   ],
   "source": [
    "def create_agg_osm_features(train_data, test_data=None):\n",
    "    osm_cols = [col for col in list(train_data) if 'osm_' in col and 'name' not in col]\n",
    "    \n",
    "    for col in osm_cols:\n",
    "        train_data[col] = train_data[col].astype('float64')\n",
    "        agg_data = (train_data.groupby('clear_city')[col].sum() / train_data[col].sum() * 100).reset_index()\n",
    "        if type(test_data) != type(None):\n",
    "            test_data = pd.merge(test_data, agg_data, on='clear_city', how='left', suffixes=('', '_agg')) \n",
    "        train_data = pd.merge(train_data, agg_data, on='clear_city', how='left', suffixes=('', '_agg'))\n",
    "        \n",
    "    if type(test_data) != type(None):\n",
    "        return train_data, test_data\n",
    "    else:\n",
    "        return train_data\n",
    "    \n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2974, 138)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = create_agg_osm_features(train_data, test_data)\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2974, 138), (279792, 139))"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data = pd.read_csv('./data/data/add_data.csv')\n",
    "\n",
    "train_data['region'] = train_data['region'].apply(lambda x: x.lower().strip())\n",
    "test_data['region'] = test_data['region'].apply(lambda x: x.lower().strip())\n",
    "\n",
    "train_data = pd.merge(train_data, add_data, on='region', how='left', suffixes=('', ''))\n",
    "test_data = pd.merge(test_data, add_data, on='region', how='left', suffixes=('', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text_floor'] = np.where(train_data['floor'].isnull(), \n",
    "                                    'unknown_floor', \n",
    "                                    train_data['floor'].apply(lambda x: str(x)))\n",
    "\n",
    "train_data.loc[train_data['floor_is_float'] == 0, 'floor'] = \\\n",
    "    train_data.loc[train_data['floor_is_float'] == 0, 'floor'].map(text_floor_replace)\n",
    "\n",
    "test_data['text_floor'] = np.where(test_data['floor'].isnull(), \n",
    "                                    'unknown_floor', \n",
    "                                    test_data['floor'].apply(lambda x: str(x)))\n",
    "\n",
    "test_data.loc[test_data['floor_is_float'] == 0, 'floor'] = \\\n",
    "    test_data.loc[test_data['floor_is_float'] == 0, 'floor'].map(text_floor_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_log = [\n",
    "                   'osm_city_closest_dist',\n",
    "                    'osm_train_stop_closest_dist',\n",
    "                    'osm_transport_stop_closest_dist',\n",
    "                    'osm_crossing_closest_dist',\n",
    "                    'reform_mean_floor_count_500'\n",
    "                   ]\n",
    "\n",
    "def log_features(data, lst):\n",
    "    for col in lst:\n",
    "        name_log_col = '_'.join(['log', col])\n",
    "        data[name_log_col] = np.log(data[col] + 0.00001)\n",
    "    return data\n",
    "        \n",
    "train_data = log_features(train_data, features_for_log)\n",
    "test_data = log_features(test_data, features_for_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(data, cols_to_filter: list):\n",
    "\n",
    "    for col in cols_to_filter:\n",
    "        data = data[(data[col] < data[col].mean() + 3 * data[col].std()) & (data[col] > data[col].mean() - 3 * data[col].std())]\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_data = filter_outliers(train_data, ['reform_mean_year_building_1000', 'reform_mean_year_building_500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_rub = pd.read_csv('eur_rub.txt', sep=',')\n",
    "usd_rub = pd.read_csv('usd_rub.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, eur_rub, on='date', how='left')\n",
    "test_data = pd.merge(test_data, eur_rub, on='date', how='left')\n",
    "\n",
    "train_data = pd.merge(train_data, usd_rub, on='date', how='left')\n",
    "test_data = pd.merge(test_data, usd_rub, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "            #'rounded_lng',\n",
    "            #'rounded_lat',\n",
    "            'date', \n",
    "             'city',\n",
    "             'street',\n",
    "             #'id',\n",
    "            'clear_city',\n",
    "            ]\n",
    "\n",
    "train_data.drop(drop_cols, axis=1, inplace=True)\n",
    "test_data.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2974, 170), (245445, 171))"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_discretize = {\n",
    "                    'osm_shops_points_in_0.001': 2,\n",
    "                    'osm_shops_points_in_0.005': 2,\n",
    "                    'osm_shops_points_in_0.0075': 2,\n",
    "                    'osm_shops_points_in_0.01': 2,\n",
    "                    'osm_finance_points_in_0.005': 2,\n",
    "                    'osm_finance_points_in_0.0075': 2,\n",
    "                    'osm_finance_points_in_0.01': 2,\n",
    "                    'osm_leisure_points_in_0.005': 2,\n",
    "                    'osm_leisure_points_in_0.01': 2,\n",
    "                    'osm_amenity_points_in_0.01': 2,\n",
    "                    'osm_transport_stop_points_in_0.005': 2,\n",
    "                    'osm_crossing_points_in_0.005': 2,\n",
    "                    'osm_crossing_points_in_0.0075': 2,\n",
    "                    'osm_crossing_points_in_0.01': 2,\n",
    "                    'reform_count_of_houses_1000': 2,\n",
    "                    'reform_count_of_houses_500': 2,\n",
    "                    'reform_mean_year_building_500': 2,\n",
    "                    'reform_mean_year_building_1000': 2,\n",
    "                    'osm_transport_stop_points_in_0.0075': 3,\n",
    "                    'osm_transport_stop_points_in_0.01': 3\n",
    "                }\n",
    "\n",
    "def bins_discretize_data(train_data, test_data, columns):\n",
    "    data = pd.concat([train_data, test_data])\n",
    "    for col, n_bins in columns.items():\n",
    "        if data[col].isnull().sum() == 0:\n",
    "            est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "            discr_col = est.fit_transform(np.array(data[col]).reshape(-1, 1))\n",
    "            name_col = 'bin_' + col\n",
    "            data[name_col] = discr_col\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bins_discretize_data(train_data, test_data, cols_to_discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((245445, 189), (2974, 189))"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[~data['per_square_meter_price'].isnull()]\n",
    "test_data = data[data['per_square_meter_price'].isnull()]\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./preprocessed_data/train_data.csv', index=False)\n",
    "test_data.to_csv('./preprocessed_data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.get_dummies(train_data, columns=['region'])\n",
    "# test_data = pd.get_dummies(test_data, columns=['region'])\n",
    "\n",
    "# region_cols = [col for col in list(train_data) if 'region' in col]\n",
    "\n",
    "# for col in region_cols:\n",
    "#     if col not in list(test_data):\n",
    "#         test_data[col] = np.zeros(test_data.shape[0])\n",
    "\n",
    "# def geo(lat_lng):\n",
    "#     geolocator = Nominatim(user_agent=\"user_agent geopy/2.2.0\")\n",
    "#     adr = geolocator.reverse(lat_lng).raw['address']\n",
    "#     try:\n",
    "#         return adr['road']\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "# def find_road(data):\n",
    "#     data['lat_lng'] = data['lat'].apply(lambda x: str(x)) + ', ' + data['lng'].apply(lambda x: str(x))\n",
    "#     data['road'] = data['lat_lng'].apply(lambda x: geo(x))\n",
    "#     return data\n",
    "\n",
    "# train_data = find_road(train_data)\n",
    "# test_data = find_road(test_data)\n",
    "\n",
    "# def fill_na_grouped_data(data, col_to_fill: str, group_cols: list, train_mode=True):\n",
    "#         name_gr = '_'.join(group_cols)\n",
    "#         fill_data_folder_name = 'fill_data'\n",
    "#         fill_data_path = os.path.join('./', fill_data_folder_name)\n",
    "#         fill_data_filename = f'{col_to_fill}_{name_gr}.csv'\n",
    "#         if train_mode:\n",
    "#             grouped_data = data.groupby(group_cols)[col_to_fill].median()\n",
    "#             grouped_data.dropna(inplace=True)\n",
    "#             grouped_data.to_csv(os.path.join('./', fill_data_folder_name, fill_data_filename))\n",
    "#         else:\n",
    "#             grouped_data = pd.read_csv(os.path.join('./', fill_data_folder_name, fill_data_filename),\n",
    "#                                        index_col=group_cols)\n",
    "#         grouped_data = grouped_data.squeeze(axis=0 if train_mode else 1)\n",
    "#         data.set_index(group_cols, inplace=True)\n",
    "#         data[col_to_fill].fillna(grouped_data, inplace=True)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         return data\n",
    "\n",
    "# train_data['rounded_lng'] = train_data['lng'].apply(lambda x: round(x, 1))\n",
    "# train_data['rounded_lat'] = train_data['lat'].apply(lambda x: round(x, 1))\n",
    "\n",
    "# test_data['rounded_lng'] = test_data['lng'].apply(lambda x: round(x, 1))\n",
    "# test_data['rounded_lat'] = test_data['lat'].apply(lambda x: round(x, 1))\n",
    "\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_mean_floor_count_500', ['rounded_lng', 'rounded_lat'])\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_mean_year_building_500', ['rounded_lng', 'rounded_lat'])\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_house_population_500', ['rounded_lng', 'rounded_lat'])\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_mean_floor_count_1000', ['rounded_lng', 'rounded_lat'])\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_mean_year_building_1000', ['rounded_lng', 'rounded_lat'])\n",
    "# train_data = fill_na_grouped_data(train_data, 'reform_house_population_1000', ['rounded_lng', 'rounded_lat'])\n",
    "\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_mean_floor_count_500', ['rounded_lng', 'rounded_lat'], False)\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_mean_year_building_500', ['rounded_lng', 'rounded_lat'], False)\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_house_population_500', ['rounded_lng', 'rounded_lat'], False)\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_mean_floor_count_1000', ['rounded_lng', 'rounded_lat'], False)\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_mean_year_building_1000', ['rounded_lng', 'rounded_lat'], False)\n",
    "# test_data = fill_na_grouped_data(test_data, 'reform_house_population_1000', ['rounded_lng', 'rounded_lat'], False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
